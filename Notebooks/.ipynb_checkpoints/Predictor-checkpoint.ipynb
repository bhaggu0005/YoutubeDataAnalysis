{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import json\n",
    "import urllib\n",
    "import datetime\n",
    "import calendar\n",
    "import re\n",
    "import  sys\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler,MinMaxScaler\n",
    "from sklearn.linear_model import  LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_database(database_name):\n",
    "    db_connection = sqlite3.connect(database_name)\n",
    "    db_crsr = db_connection.cursor()\n",
    "    X = []\n",
    "    Y = [] # LikeCount\n",
    "    \n",
    "    try:\n",
    "        db_crsr.execute(\"Select likeCount,viewCount,commentCount,dislikeCount,duration from Videos\")\n",
    "        rows=db_crsr.fetchall()\n",
    "        for row in rows:\n",
    "            Y.append(row[0] if row[0] else 0) #likeCount\n",
    "            \n",
    "            # numerical features\n",
    "            viewCount=row[1] if row[1] else 0\n",
    "            commentCount=row[2] if row[2] else 0\n",
    "            dislikeCount=row[3] if row[3] else 0\n",
    "            duration=row[4] if row[4] else 0\n",
    "              \n",
    "            X.append([\n",
    "                viewCount, \n",
    "                commentCount,\n",
    "                dislikeCount,\n",
    "                duration,\n",
    "            ])\n",
    "\n",
    "    except (sqlite3.OperationalError,e):\n",
    "        print ('sqlite3.OperationalError:',e)\n",
    "\n",
    "    db_connection.close()\n",
    "    return X,Y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def real_video_fetch(video_id):\n",
    "   api_key=\"AIzaSyAkNjqcFjNT86o-m3uloLS-EzhR1aCtlQE\"\n",
    "   numerical_features_real=[]\n",
    "   \n",
    "   url = \"https://www.googleapis.com/youtube/v3/videos?id=\" + video_id + \"&key=\" + api_key + \"&part=status,statistics,contentDetails,snippet\"\n",
    "   response = urllib.request.urlopen(url).read()\n",
    "   data = json.loads(response)\n",
    "   all_data = data['items']\n",
    "   #print (all_data)\n",
    "\n",
    "   #Snippet\n",
    "   channelId = all_data[0]['snippet']['channelId']\n",
    "   channelTitle = all_data[0]['snippet']['channelTitle']\n",
    "   title = all_data[0]['snippet']['title']\n",
    "   print ('title :',title)\n",
    "   description = all_data[0]['snippet']['description']\n",
    "   category_id = all_data[0]['snippet']['categoryId']\n",
    "   publishedAt = all_data[0]['snippet']['publishedAt']\n",
    "   #publishedAt\t= int(strict_rfc3339.rfc3339_to_timestamp(publishedAt))\n",
    "   currentTime\t= datetime.datetime.utcnow() # current time as rtf3339\n",
    "   currentTime\t= datetime.datetime.timetuple(currentTime) # current time as timetuple\n",
    "   currentTime\t= calendar.timegm(currentTime) # current time as epoch timestamp\n",
    "   #life = currentTime - publishedAt\n",
    "\n",
    "   #Content Details\n",
    "   defintion = all_data[0]['contentDetails']['definition']\n",
    "   caption = all_data[0]['contentDetails']['caption']\n",
    "   licensedContent = all_data[0]['contentDetails']['licensedContent']\n",
    "   dimension = all_data[0]['contentDetails']['dimension']\n",
    "\n",
    "   duration = all_data[0]['contentDetails']['duration']\n",
    "   duration_w = re.search(r\"(\\d+)w\", duration, re.I)\n",
    "   duration_w = int(duration_w.group(1)) if duration_w else 0\n",
    "   duration_d = re.search(r\"(\\d+)d\", duration, re.I)\n",
    "   duration_d = int(duration_d.group(1)) if duration_d else 0\n",
    "   duration_h = re.search(r\"(\\d+)h\", duration, re.I)\n",
    "   duration_h = int(duration_h.group(1)) if duration_h else 0\n",
    "   duration_m = re.search(r\"(\\d+)m\", duration, re.I)\n",
    "   duration_m = int(duration_m.group(1)) if duration_m else 0\n",
    "   duration_s = re.search(r\"(\\d+)s\", duration, re.I)\n",
    "   duration_s = int(duration_s.group(1)) if duration_s else 0\n",
    "   duration = 0\n",
    "   duration += duration_w * 7 * 24 * 60 * 60\n",
    "   duration += duration_d * 24 * 60 * 60\n",
    "   duration += duration_h * 60 * 60\n",
    "   duration += duration_m * 60\n",
    "   duration += duration_s * 1\n",
    "   durationCategory\t= \"short\"\n",
    "   durationCategory\t= \"medium\" if duration_m >= 4 else \"short\"\n",
    "   durationCategory\t= \"long\" if duration_m >= 20 else \"medium\"\n",
    "\n",
    "   try:\n",
    "\t   allowed = ','.join(all_data[0][\"contentDetails\"][\"regionRestriction\"][\"allowed\"])\n",
    "   except Exception:\n",
    "\t   allowed = None\n",
    "   try:\n",
    "\t   allowedCount = len(all_data[0][\"contentDetails\"][\"regionRestriction\"][\"allowed\"])\n",
    "   except Exception:\n",
    "\t   allowedCount = 0\n",
    "\n",
    "   # recordingDetails\n",
    "   try:\n",
    "\t   recordingDate = all_data[0][\"recordingDetails\"][\"recordingDate\"]\n",
    "\t   recordingDate = int(strict_rfc3339.rfc3339_to_timestamp(recordingDate))\n",
    "   except Exception:\n",
    "\t   recordingDate = None\n",
    "   try:\n",
    "\t   latitude = all_data[0][\"recordingDetails\"][\"location\"][\"latitude\"]\n",
    "   except Exception:\n",
    "\t   latitude = None\n",
    "   try:\n",
    "\t   longitude = all_data[0][\"recordingDetails\"][\"location\"][\"longitude\"]\n",
    "   except Exception:\n",
    "\t   longitude = None\n",
    "\n",
    "   # status\n",
    "   publicStatsViewable\t= int(all_data[0]['status']['publicStatsViewable'])\n",
    "   privacyStatus = all_data[0]['status']['privacyStatus']\n",
    "   license\t= all_data[0]['status']['license']\n",
    "   embeddable = int(all_data[0]['status']['embeddable'])\n",
    "\n",
    "   #Statistics\n",
    "   commentCount = int(all_data[0]['statistics']['commentCount'])\n",
    "   viewCount = int(all_data[0]['statistics']['viewCount'])\n",
    "   favoriteCount = int(all_data[0]['statistics']['favoriteCount'])\n",
    "   likeCount = int(all_data[0]['statistics']['likeCount'])\n",
    "   dislikeCount = int(all_data[0]['statistics']['dislikeCount'])\n",
    "\n",
    "\n",
    "\n",
    "   numerical_features_real.append([\n",
    "  \t  viewCount,\n",
    "   \t  commentCount,\n",
    "      dislikeCount,\n",
    "      duration,\n",
    "      ])\n",
    "\n",
    "   return (numerical_features_real,likeCount)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_predictor(videoids):\n",
    "    X,Y=extract_database('youtube.db')\n",
    "    scaler = MinMaxScaler(feature_range=(-2,2))\n",
    "    for videoid in videoids:\n",
    "        x_test_real,likeCount=real_video_fetch(videoid)\n",
    "        #Feature Scaling\n",
    "        numerical_features_total=np.append(X,x_test_real,axis=0)\n",
    "        \n",
    "        X_total_scaled=scaler.fit_transform(numerical_features_total) #numerical_features\n",
    "        x_test_real_scaled=X_total_scaled[X_total_scaled.shape[0]-1]\n",
    "        x_test_real_scaled=x_test_real_scaled.reshape(1,-1)\n",
    "        X_scaled=X_total_scaled[:X_total_scaled.shape[0]-1] #removing real\n",
    "        #diff classifiers\n",
    "        print ('Random Forest: ')\n",
    "        rfg=RandomForestRegressor()\n",
    "        rfg.fit(X_scaled,Y)\n",
    "        print ('video_id : ', videoid)\n",
    "        print('PREDICTED: ',rfg.predict(x_test_real_scaled))\n",
    "        print('ACTUAL: ',likeCount,'\\n')\n",
    "        lr=LinearRegression()\n",
    "        lr.fit(X_scaled,Y)\n",
    "        print ('Linear Regresion: ')\n",
    "        print ('video_id : ', videoid)\n",
    "        print('PREDICTED: ',lr.predict(x_test_real_scaled))\n",
    "        print('ACTUAL: ',likeCount,'\\n')\n",
    "        if videoid==videoids[len(videoids)-1]:\n",
    "                train_test_check(X_scaled,Y)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_check(x,y):\n",
    "    xtrain,xtest,ytrain,ytest = train_test_split(x,y,train_size=.8,random_state=2)\n",
    "    xtrain=np.array(xtrain)\n",
    "    ytrain=np.array(ytrain)\n",
    "    ytest=np.array(ytest)\n",
    "    rfg=RandomForestRegressor(random_state=2)\n",
    "    rfg.fit(xtrain,ytrain)\n",
    "    print('\\nTRAIN TEST CHECK\\nRandom Forest Regressor\\nTraining Score:',rfg.score(xtrain,ytrain))\n",
    "    print('\\nTesting Score:',rfg.score(xtest,ytest))\n",
    "    lr=LinearRegression()\n",
    "    lr.fit(xtrain,ytrain)\n",
    "    print('Linear Regression\\nTraining Score:',lr.score(xtrain,ytrain))\n",
    "    print('\\nTesting Score:',lr.score(xtest,ytest),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title : Daru Desi (Full Video Song) | Cocktail | Saif Ali Khan, Deepika Padukone & Diana Penty\n",
      "Random Forest: \n",
      "video_id :  3nA1hmKCRpE\n",
      "PREDICTED:  [ 77791.]\n",
      "ACTUAL:  53642 \n",
      "\n",
      "Linear Regresion: \n",
      "video_id :  3nA1hmKCRpE\n",
      "PREDICTED:  [ 118073.08844143]\n",
      "ACTUAL:  53642 \n",
      "\n",
      "title : Zaalima - Lyrical | Raees | Shah Rukh Khan & Mahira Khan | Arijit Singh & Harshdeep Kaur | JAM8\n",
      "Random Forest: \n",
      "video_id :  hhdSyBHuI88\n",
      "PREDICTED:  [ 402413.6]\n",
      "ACTUAL:  220691 \n",
      "\n",
      "Linear Regresion: \n",
      "video_id :  hhdSyBHuI88\n",
      "PREDICTED:  [ 303148.36806707]\n",
      "ACTUAL:  220691 \n",
      "\n",
      "title : Lat Lag Gayee - Lyrical Video | Race 2 | Saif Ali Khan, Jacqueline Fernandez | Benny Dayal, Shalmali\n",
      "Random Forest: \n",
      "video_id :  KxCjVIFxZNo\n",
      "PREDICTED:  [ 300543.3]\n",
      "ACTUAL:  248209 \n",
      "\n",
      "Linear Regresion: \n",
      "video_id :  KxCjVIFxZNo\n",
      "PREDICTED:  [ 408540.99489283]\n",
      "ACTUAL:  248209 \n",
      "\n",
      "title : Sajjad Ali - Lagaya Dil (Official Video)\n",
      "Random Forest: \n",
      "video_id :  Fb0OTqLotxU\n",
      "PREDICTED:  [ 87225.8]\n",
      "ACTUAL:  54781 \n",
      "\n",
      "Linear Regresion: \n",
      "video_id :  Fb0OTqLotxU\n",
      "PREDICTED:  [ 48887.09397553]\n",
      "ACTUAL:  54781 \n",
      "\n",
      "title : Hawayein - Official Lyric Video | Anushka | Shah Rukh | Pritam | Arijit\n",
      "Random Forest: \n",
      "video_id :  cYOB941gyXI\n",
      "PREDICTED:  [ 533843.6]\n",
      "ACTUAL:  437032 \n",
      "\n",
      "Linear Regresion: \n",
      "video_id :  cYOB941gyXI\n",
      "PREDICTED:  [ 644237.74655811]\n",
      "ACTUAL:  437032 \n",
      "\n",
      "\n",
      "TRAIN TEST CHECK\n",
      "Random Forest Regressor\n",
      "Training Score: 0.976681191498\n",
      "\n",
      "Testing Score: 0.896195724375\n",
      "Linear Regression\n",
      "Training Score: 0.83757168387\n",
      "\n",
      "Testing Score: 0.858575031801 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "videoids=['3nA1hmKCRpE','hhdSyBHuI88','KxCjVIFxZNo','Fb0OTqLotxU','cYOB941gyXI']\n",
    "init_predictor(videoids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
